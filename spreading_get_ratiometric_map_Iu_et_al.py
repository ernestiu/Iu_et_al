
"""
Created on Fri May 29 13:52:27 2020

@author: ernes
"""

import numpy as np
from skimage import io, filters
import matplotlib.pyplot as plt
from k_means_segmentation import k_means_seg, binary_operation, remove_top_percentile_pix
from drift_correction import optical_flow_registration, pystackreg_registration, drift_corr, sub_pixel_registration
from image_corr_module import photobleaching_corr, uneven_corr, bg_subtraction, bleedthru_corr, hybrid_median_filtering, remove_empty_frames, remove_spurious_pixels
import os
from proprietary_image_readers import lif_image_reader, nd2_image_reader
from datetime import datetime
import tifffile
import matplotlib.colors as colors

# flags

save = True

photobleaching_first = False
photobleaching_end = False

remove_empty_slices = False # if there's empty frames in the stacks, you want to remove them here
frame_to_remove = None # if you want to remove some problematic frames, put the indeces of the frames here and enable remove_empty_slices

shading_correction = True
background_subtraction = True
bleedthru_correction = False
yfp_co, cfp_co = 0.052, 0.3072 # bleedthrough coefficients 



drift_corrrection = False # to correct for drifting
subpixel_registration = False # to align images between channels
beads_registration = False # to align images between channels based on beads images


ML_segmentation = False
clusters = 3 # define the number of clusters used for k means segmentation - higher means a lower threshold
sig_value = 0.4  # define the sigma value for gaussian blur
smallest_cell_size = 150  # objects smaller than this number (pixel) will be filtered out
fill_holes_on_masks = True # fill holes after segmentation
hole_area = 2000 # only holes smaller than this threshold will be filled
remove_high_intensity_pixels = False # only enable when handling FRET images

spatial_filter_before = True # a gaussian filter before the ratiometric calculation
spatial_filter_after = True # a median filter after the ratiometric calculation

binning = False
bin_size = 2

read_img = 3 # 1 = nd2, 2 = lif, 3 = tif



image_path = '/image.tif'

# these bg_int numbers will override the bg_int generated by the bg subtraction algorithm
den_bg_int = None
num_bg_int = None
seg_bg_int = None

# put the denominator & numerator channel indexes here
d_channel_idx = 2 # denominator
n_channel_idx = 1 # numerator
segment_channel_idx = 0

# end of flags

pixel_size = 1 # don't change; if the image reader detects a pixel size value from the metadata, this will be replaced by that number.

### import nd2 here ###
if read_img == 1: 
    image_stack, fields_of_view, image_name, image_metadata = nd2_image_reader(image_path)
    # extract the pixel size from the metadata
    pixel_size = image_metadata['pixel_microns']
    if image_metadata['z_levels'] == []: # if there's no z stack
        image_metadata['z_levels'] = 1
    else:
        image_metadata['z_levels'] = len(image_metadata['z_levels'])


### import lif here ###
if read_img == 2: image_stack, fields_of_view, image_name = lif_image_reader(image_path)

### import tiff here ###
if read_img == 3:
    image_stack = io.imread(image_path)
    fields_of_view = [0]
    if len(image_stack.shape) == 3: # a multi-channel single frame image
        image_stack = np.expand_dims(np.expand_dims(image_stack, axis=0), axis=0) # add a fake axis twice 
    if len(image_stack.shape) == 4: # a multi-channel timelapse image
        image_stack = np.expand_dims(image_stack, axis=0)# add a fake axis once 
    if len(image_stack.shape) == 5: # a multi-position, multi-channel timelapse image
         fields_of_view = range(image_stack.shape[0])
    image_name = os.path.splitext(os.path.basename(image_path))[0]
    image_metadata = {'z_levels' : 1}
    

for ff, fov in enumerate(fields_of_view):
    
    if len(fields_of_view) != 1: print('Processing FOVs: {0}/{1}'.format(ff+1, len(fields_of_view))) # only print the process if fov is larger than 1


    # extract images from the stack
    den = image_stack[fov,:,:,:,d_channel_idx].copy()
    num = image_stack[fov,:,:,:,n_channel_idx].copy()
    segment_channel = image_stack[fov,:,:,:,segment_channel_idx].copy()
    # segment_channel = segment_channel+den # to improve the cell segmentation
    
    if remove_empty_slices:
  
        den = remove_empty_frames(den, axis_to_remove_images = 0, indices = frame_to_remove)
        num = remove_empty_frames(num, axis_to_remove_images = 0, indices = frame_to_remove)
        segment_channel = remove_empty_frames(segment_channel, axis_to_remove_images = 0, indices = frame_to_remove) 
        

#########    
    # illumination correction
    if shading_correction:
        
        if fov == fields_of_view[0]: # only import shading image in the first loop
            if read_img == 3:
                shading_image_stack = io.imread(os.path.dirname(image_path) + '/' + 'shading image.tif')    
                shading_image_stack = np.expand_dims(shading_image_stack, axis=0) # add another axis
            else:
                shading_image_stack, _, __, ___ = nd2_image_reader(os.path.dirname(image_path) + '/' + 'shading image.nd2')
            
            if shading_image_stack.shape[4] == image_stack.shape[4]: # if the no. of channels are the same in the image_stack and shading_image_stack
                # take the mean of all the frames
                den_shading_img = np.median(shading_image_stack[0,:,:,:,d_channel_idx], axis=0)
                num_shading_img = np.median(shading_image_stack[0,:,:,:,n_channel_idx], axis=0) 
                segment_channel_shading_img = np.median(shading_image_stack[0,:,:,:,segment_channel_idx], axis=0)
            
            else: # if the no. of channels are NOT the same in the image_stack and shading_image_stack
                # take the mean of all the frames
                print('Alert! shading_correction: the no. of channels are NOT the same in the image_stack and shading_image_stack')
                den_shading_img = np.mean(shading_image_stack[0,:,:,:,1], axis=0)
                num_shading_img = np.mean(shading_image_stack[0,:,:,:,0], axis=0) 
                segment_channel_shading_img = np.mean(shading_image_stack[0,:,:,:,2], axis=0)
            
            
            del shading_image_stack # only delete shading image in the first loop
            

        for n in range(den.shape[0]):
            den[n,:,:] = uneven_corr(shading_img=den_shading_img, img=den[n,:,:], psudo_bg = False)
            num[n,:,:] = uneven_corr(shading_img=num_shading_img, img=num[n,:,:], psudo_bg = False)
            segment_channel[n,:,:] = uneven_corr(shading_img=segment_channel_shading_img, img=segment_channel[n,:,:], psudo_bg = False)
       
        
        
        print('Shading correction done.')
            
########

    if subpixel_registration:
        
        for n in range(den.shape[0]):
            
            num[n,:,:], num_xoff, num_yoff = optical_flow_registration(segment_channel[n,:,:], num[n,:,:])#, upsample_factor=20, manual_shift=(0,0))
            print("Numerator channel shifted by: ", round(num_xoff, 2), round(num_yoff, 2))
            
            den[n,:,:], den_xoff, den_yoff = optical_flow_registration(segment_channel[n,:,:], den[n,:,:])#, upsample_factor=20, manual_shift=(-0.3,0)) # minus is moving up
            print("Denominator channel shifted by: ", round(den_xoff, 2), round(den_yoff, 2))
        
        print('Subpixel image registration done.')
        
######## 

    if beads_registration:
        
        
        beads_img = io.imread('/Users/ernestiu/Library/Group Containers/G69SCX94XU.duck/Library/Application Support/duck/Volumes.noindex/Images Server/2023/2023-10-30/bead_image_position_6_test.tif')
        
        
        from pystackreg import StackReg
        sr = StackReg(StackReg.RIGID_BODY)
        tmats_d = sr.register(beads_img[:,:,n_channel_idx], beads_img[:,:,d_channel_idx])
        tmats_s = sr.register(beads_img[:,:,n_channel_idx], beads_img[:,:,segment_channel_idx])
        new_beads = np.empty(beads_img.shape)
        new_beads[:,:,n_channel_idx]  = beads_img[:,:,n_channel_idx]
        new_beads[:,:,d_channel_idx] = sr.transform(beads_img[:,:,d_channel_idx], tmat=tmats_d)
        new_beads[:,:,segment_channel_idx] = sr.transform(beads_img[:,:,segment_channel_idx], tmat=tmats_s)
        
        tifffile.imwrite(os.path.dirname(image_path) + '/' + 'beads_corr.tif', new_beads)
        
    

        for n in range(den.shape[0]):

            
            den[n,:,:] = sr.transform(den[n,:,:], tmat=tmats_d)
            segment_channel[n,:,:] = sr.transform(segment_channel[n,:,:], tmat=tmats_s)
        
        print('Beads image registration done.')

########
                      
    if background_subtraction:
        
        all_den_bg_value, all_num_bg_value, all_segment_channel_value  = [],[],[]
        
        for n in range(den.shape[0]):
           
            # only show the first frame
            den[n,:,:], den_bg_value = bg_subtraction(den[n,:,:], show_image = n==0, bg_value = np.median(den[n,:,:]))
            all_den_bg_value.append(den_bg_value)
            num[n,:,:], num_bg_value = bg_subtraction(num[n,:,:], show_image = n==0, bg_value = np.median(num[n,:,:])) 
            all_num_bg_value.append(num_bg_value)
            segment_channel[n,:,:], segment_bg_value = bg_subtraction(segment_channel[n,:,:], show_image = n==0, bg_value = np.median(segment_channel[n,:,:]))
            all_segment_channel_value.append(segment_bg_value)

         
        if den.shape[0] > 1: # plot the background values for time-series images 
        
            fig, ax1 = plt.subplots()
            color_1, color_2 = 'tab:red', 'tab:blue'
            ax1.set_xlabel('Frames')
            ax1.set_ylabel('Denominator Background', color = color_1)
            ax1.plot(all_den_bg_value, color = color_1)
            ax1.tick_params(axis ='y', labelcolor = color_1)
             
            # Adding Twin Axes to the plot 
            ax2 = ax1.twinx()    
            ax2.set_ylabel('Numerator Background', color = color_2)
            ax2.plot(all_num_bg_value, color = color_2)
            ax2.tick_params(axis ='y', labelcolor = color_2)
            plt.title('Background subtraction', fontweight ="bold")
            if 0 in all_den_bg_value or 0 in all_num_bg_value:
                ax1.set_ylim([np.mean(all_den_bg_value)*0.99, np.max(all_den_bg_value)*1.1])
                ax2.set_ylim([np.mean(all_num_bg_value)*0.99, np.max(all_num_bg_value)*1.1])
            plt.show()
    
                
        else: # print the background values for still frames
            print('Background of the denominator: ' + str(all_den_bg_value[0])) 
            print('Background of the numerator: ' + str(all_num_bg_value[0])) 
            print('Background of the segmented channel image: ' + str(all_segment_channel_value[0]))
        
        print('Background subtraction done.') 

#########

    if binning:
        from skimage import transform
        binned_num = np.empty((num.shape[0], 
                               int(np.ceil(num.shape[1]/bin_size)), 
                              int(np.ceil(num.shape[2]/bin_size))), 
                              dtype=num.dtype)
        binned_den = binned_num.copy()
        binned_segment_img = binned_num.copy()
        
        for s in range(num.shape[0]):
            binned_num[s,:,:] = transform.downscale_local_mean(num[s,:,:], (bin_size,bin_size))
            binned_den[s,:,:] = transform.downscale_local_mean(den[s,:,:], (bin_size,bin_size))
            binned_segment_img[s,:,:] = transform.downscale_local_mean(segment_channel[s,:,:], (bin_size,bin_size))
            
        num = binned_num
        den = binned_den
        segment_channel = binned_segment_img
        
        if fov == fields_of_view[0]: # only multiple the pixel size in the first loop
            pixel_size = pixel_size * bin_size
        
        
#########

    if bleedthru_correction:
        
        for n in range(num.shape[0]):
            
            # only show image in the first loop
            num[n,:,:] = bleedthru_corr(segment_channel[n,:,:], num[n,:,:], den[n,:,:], 
                                        yfp_coeff = yfp_co, cfp_coeff = cfp_co, show_image= n == 0)
                
            # the bleedthrough corrected image tends to be noisy
            num[n,:,:] = filters.gaussian(num[n,:,:], sigma=sig_value, preserve_range=True)
            
        print('Bleedthrough correction done.')
          

                   
########

    # photobleaching correction 
    if photobleaching_first:
    
        den = photobleaching_corr(den, thresholded_img = False, title = 'Denominator photobleaching correction')
        num = photobleaching_corr(num, thresholded_img = False, title = 'Numerator photobleaching correction')


        
    # create a ratiometric image 
    for f in range (num.shape[0]):
        num[f][np.where(den[f] == 0)] = 0 # set all the 0 pixels in den 0 in num.
        
        if spatial_filter_before:
            
            num[f,:,:] = filters.gaussian(num[f,:,:], sigma=sig_value, preserve_range=True)
            den[f,:,:] = filters.gaussian(den[f,:,:], sigma=sig_value, preserve_range=True)
        
    ratiometric_img = np.divide(num, den, where=den!=0)

########
    
    if drift_corrrection:   
        segment_channel, tmats = drift_corr(segment_channel)
        np.save(os.path.dirname(image_path) + '/' + image_name +'_tmats.npy', tmats) # save the transformation matrix
        den, _ = drift_corr(den, tmat = tmats)
        num, _ = drift_corr(num, tmat = tmats)
        ratiometric_img, _ = drift_corr(ratiometric_img, tmat = tmats)
        
#########

    corrected_imgs = np.empty((image_metadata['z_levels'], den.shape[0],# z, time,
                                den.shape[1], den.shape[2], 3), dtype=image_stack.dtype) # xy axes and number of channels   

    
    corrected_imgs[:,:,:,:,2] = den
    corrected_imgs[:,:,:,:,1] = num
    corrected_imgs[:,:,:,:,0] = segment_channel

    
#########
        
    # create place holders for the segmented ratiometric image and binary mask
    all_masks = np.empty(ratiometric_img.shape)
    ratiometric_img_thres = np.empty(ratiometric_img.shape)
    
    if ML_segmentation:   # ML segmentation
    
        import pickle
        import sys
        
        # locate the feature extraction function and the trained ML model
        machine_learning_module_path = '/Users/ernestiu/Library/CloudStorage/GoogleDrive-iamernestiu@gmail.com/My Drive/Research/Python codes/Machine learning codes/'
        sys.path.append(machine_learning_module_path)
        
        from feature_extraction import feature_extraction
    
        loaded_model = pickle.load(open(machine_learning_module_path + 'WF segmentation', 'rb'))


    for jj in range(segment_channel.shape[0]):
        
        if np.mean(segment_channel[jj,:,:]) == 0: # skip blank frames
            print('Found a blank frame at: ' + str(jj+1) + '/' + str(ratiometric_img.shape[0]))
            all_masks[jj] = np.zeros(segment_channel[jj,:,:].shape)
            ratiometric_img[jj,:,:] = np.zeros(segment_channel[jj,:,:].shape)
            ratiometric_img_thres[jj,:,:] = np.zeros(segment_channel[jj,:,:].shape)
            
        else:
            if ML_segmentation:  # using a pre-trained ML model
                
                # remove the brightest Nth percentile pixels (optional)
                segment_channel[jj,:,:] = remove_top_percentile_pix(segment_channel[jj,:,:], percentile=99)  
                  
                img_features = feature_extraction(segment_channel[jj,:,:])
                results = loaded_model.predict(img_features)
                segmented_img = results.reshape((segment_channel[jj,:,:].shape))
                segmented_img = segmented_img == 2 # the cell is labelled as 2
                # hue = segmented_img == 3 # the hue is labelled as 3
                
            if not ML_segmentation: # using K-means
                # for soluble flurescent marker, use 3. for actin, use 4.
                kmeans, segmented_img = k_means_seg(segment_channel[jj,:,:], show_result= jj == 0, K=clusters) 
                
        mask = binary_operation(segmented_img, small_obj=smallest_cell_size, fill_holes = fill_holes_on_masks, hole_area_thres=hole_area)
       
        if np.max(mask) == False:
            print('The binary mask is empty. Please adjust the segmentation algorithm.')
            pass
            
        
        else:
            max_allowed_intensity = (2**16-1)/1000 # if the pixel value is higher than 65.535 (set it to 0 because it overflows the pixel and is too high to be true)
           
            if np.max(ratiometric_img[jj,:,:][mask==True]) >= max_allowed_intensity: # to avoid pixel overflow within the cell
                
                overflow_pixels = np.where(ratiometric_img[jj,:,:] > max_allowed_intensity)
                ratiometric_img[jj,:,:][overflow_pixels] = 0
                # plt.imshow(mask, 'Greys_r')
                # plt.plot(overflow_pixels[1], overflow_pixels[0], 'r.', alpha=0.5)
                # plt.title('Overflow pixels (red)')
                # plt.axis('off')
                # plt.show()
                print('Pixel overflow detected in the ratiometric image! ' + str(len(overflow_pixels[0])) + ' pixels')
                
        if spatial_filter_after: # filter before applying the mask           
            # ratiometric_img[jj,:,:] = filters.gaussian(ratiometric_img[jj,:,:], sigma=sig_value, preserve_range=True)
            ratiometric_img[jj,:,:] = hybrid_median_filtering(ratiometric_img[jj,:,:])

        all_masks[jj] = mask
        ratiometric_img[jj,:,:][np.where(all_masks[jj]==False)] = 0
        ratiometric_img[jj,:,:] = ratiometric_img[jj,:,:]*1000
        
        if remove_high_intensity_pixels:
            ratiometric_img[jj,:,:] = remove_spurious_pixels(ratiometric_img[jj,:,:], threshold = 1000)
            
        
        ratiometric_img_thres[jj,:,:] = ratiometric_img[jj,:,:]
        
        if jj == 0: # display the image for the first frame
            
            custom_cmap = colors.LinearSegmentedColormap.from_list("Meyer_lab_LUT", ["#352a87","#1685d4","#66be85","#febd3c","#fafb2a"])
            custom_cmap.set_under(color='black')
            
            if not ML_segmentation:
                

                mean = np.mean(ratiometric_img_thres[jj,:,:])
                std = np.std(ratiometric_img_thres[jj,:,:])
                plt.imshow(ratiometric_img_thres[jj,:,:], cmap=custom_cmap)#, vmin=mean, vmax=mean+std*3)
                plt.axis('off')
                plt.colorbar()
                plt.show()

            if ML_segmentation:
                fig, (ax1, ax2) = plt.subplots(1, 2)
                ax1.imshow(segment_channel[jj,:,:], cmap='gray_r')
                ax1.imshow(mask, cmap='Reds', alpha=0.5)
                ax1.set_title('ML segmentation')
                ax1.axis('off')
                
                
                axis_2 = ax2.imshow(ratiometric_img_thres[jj,:,:], cmap=custom_cmap)#, vmin=100, vmax=500)
                cax = fig.add_axes([ax2.get_position().x1+0.01,ax2.get_position().y0,0.02,ax2.get_position().height])
                fig.colorbar(axis_2, ax=ax2, shrink=0.7, cax=cax)
                ax2.set_title('ML ratiometric image')
                ax2.axis('off')
                plt.show()

        print('Segmentation progress: {0}/{1}'.format(jj+1, ratiometric_img.shape[0]))
            
 

    if photobleaching_end:
        ratiometric_img_thres = photobleaching_corr(ratiometric_img_thres, thresholded_img = True, title = 'Ratiometric image photobleaching correction')
    

        
    if save:
        
        def append_str(str_1, str_2, append = False):
            '''
            This simple function appends a string (str_2) to another string (str_1) based on condition. 
            If append is True, the function will combine str_1 and str_2, and return a combined string.
            '''
            if append == True:
                return str_1 + str_2
            else: 
                return str_1
        
        final_image_name = append_str(str_1 = os.path.dirname(image_path) + '/' + image_name +'_ratiometric', 
                                      str_2 = '_fov_' + str(fov+1), append = len(fields_of_view)>1)
                
        
        tiff_metadata = {'unit': 'micron', 'axes': 'TYX'}
        
        ratiometric_img_thres = ratiometric_img_thres.astype(segment_channel.dtype)
        tifffile.imwrite(final_image_name + '.tif', ratiometric_img_thres, imagej=True,
                         resolution=(1/pixel_size, 1/pixel_size), metadata=tiff_metadata) 
           
            
        final_corrected_image_name = append_str(str_1 = os.path.dirname(image_path) + '/' + image_name +'_corrected_imgs', 
                                      str_2 = '_fov_' + str(fov+1), append = len(fields_of_view)>1)
        
    
        
        corrected_imgs = np.transpose(corrected_imgs, axes=[1, 0, 4, 2, 3]) # To configure the axes order, you need to put in the old axe indeces in the new order
        corr_tiff_metadata = {'unit': 'um', 'axes': 'TZCYX'} 
        tifffile.imwrite(final_corrected_image_name + '.tif', corrected_imgs, imagej=True, 
                          resolution=(1/pixel_size, 1/pixel_size), metadata=corr_tiff_metadata)

        
        now = datetime.now()
        dt_string = now.strftime("%d/%m/%Y %H:%M:%S")# dd/mm/YY H:M:S
     
        metadata = open(os.path.dirname(image_path) + '/' + image_name + "_processing metadata.txt", "w")
        metadata.write(
            'The image was processed on: ' + dt_string + '\n' + 
            'save = ' + str(save) + '\n' +
            'photobleaching_first = ' + str(photobleaching_first) + '\n' +
            'photobleaching_end = ' + str(photobleaching_end) + '\n' +
            'remove_empty_slices = ' + str(remove_empty_slices) + '\n' +
            'frame_to_remove = ' + str(frame_to_remove) + '\n' +
            'shading_correction = ' + str(shading_correction) + '\n' +
            'background_subtraction = ' + str(background_subtraction) + '\n' +
            'bleedthru_correction = ' + str(bleedthru_correction)+ '\n' +    
            'yfp_co, cfp_co = ' + str(yfp_co) + ', ' + str(cfp_co) + '\n' +  
            'drift_corrrection = ' + str(drift_corrrection) + '\n' +
            'subpixel_registration = ' + str(subpixel_registration) + '\n' +
            'beads_registration = ' + str(beads_registration) + '\n' +
            'ML_segmentation = ' + str(ML_segmentation) + '\n' +
            'clusters = ' + str(clusters) + '\n' +
            'sig_value = ' + str(sig_value) + '\n' 
            'smallest_cell_size = ' + str(smallest_cell_size) + '\n' +
            'fill_holes_on_masks = ' + str(fill_holes_on_masks) + '\n' +
            'hole_area = ' + str(hole_area) + '\n' +
            'remove_high_intensity_pixels = ' + str(remove_high_intensity_pixels) + '\n' +
            'spatial_filter_before = ' + str(spatial_filter_before) + '\n' +
            'spatial_filter_after = ' + str(spatial_filter_after) + '\n' +
            'binning = ' + str(binning) + '\n' +
            'bin_size = ' + str(bin_size) + '\n'
            )
        if background_subtraction:
            metadata.write('all_den_bg_value, all_num_bg_value, all_segment_channel_value = ' + str(all_den_bg_value) + ', ' + str(all_num_bg_value) + ', ' + str(all_segment_channel_value) + '\n')
        if subpixel_registration:
            metadata.write('Numerator channel shifted by: ' + str(round(num_xoff, 2)) + ', ' + str(round(num_yoff, 2)) + '\n' +
                           'Denominator channel shifted by: ' + str(round(den_xoff, 2)) + ', ' + str(round(den_yoff, 2)) + '\n')
        metadata.close()
    
        